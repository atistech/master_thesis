# Activation functions of neural networks
def activations():
    return ["relu", "sigmoid", "softmax", "softplus", "softsign", "tanh", "selu"]

# Optimizer functions of neural networks
def optimizers():
    return ["rmsprop", "adam"]